{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import operator\n",
    "\n",
    "def get_most_frquen_ans(answers):\n",
    "    result = {}\n",
    "    for i in range(10):\n",
    "        result[answers[i]['answer']] = 1\n",
    "    print(result)\n",
    "    for i in range(10):\n",
    "        result[answers[i]['answer']] +=1\n",
    "    print('after :', result)\n",
    "    return max(result.items(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'oval': 1, 'semi circle': 1, 'curved': 1, 'double curve': 1, 'banana': 1, 'wavy': 1, 'twisting': 1}\n",
      "after : {'oval': 2, 'semi circle': 2, 'curved': 5, 'double curve': 2, 'banana': 2, 'wavy': 2, 'twisting': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'curved'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试下方法\n",
    "json_obj = json.load(open(\"./test.json\", \"r\"))\n",
    "get_most_frquen_ans(json_obj['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取图片的features\n",
    "#使用标准coco的图片，从https://cs.stanford.edu/people/karpathy/deepimagesent/下可以下载到这些图片的features\n",
    "#这样可以不用训练，直接拿到图片的feature\n",
    "import scipy.io as io\n",
    "#加载训练好的图片的feature到feature_struct中\n",
    "#生成图片id与feature列标的对应数据 img_map\n",
    "def generate_coco_image_feature(img_feats_file, img_ids_feats):\n",
    "    feature_struct = io.loadmat(img_feats_file)\n",
    "    img_vgg_features = feature_struct['feats']\n",
    "    img_ids_feats_col = open(img_ids_feats).read().splitlines()\n",
    "    img_map = {}\n",
    "    for ids in img_ids_feats_col:\n",
    "        ids_split = ids.split()\n",
    "        img_map[ids_split[0]] = int(ids_split[1])\n",
    "    return img_vgg_features, img_map\n",
    "\n",
    "#根据图片id,取得相应的特征数据\n",
    "def get_image_matrix(feature_struct, img_map, image_ids):\n",
    "    rows = len(image_ids)\n",
    "    img_matrix = np.zeros((rows, feature_struct.shape[0]))\n",
    "    for i in range(rows):\n",
    "        img_matrix[i,:] = feature_struct[:,img_map[image_ids[i]]]\n",
    "    return img_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理文字\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format(\"./sentiment/GoogleNews-vectors-negative300.bin.gz\", binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentencVector(model, sentence):\n",
    "    sen = str(sentence).lower()\n",
    "    words = word_tokenize(sen)\n",
    "    #words = [w for w in words if w not in stop_words]\n",
    "    words = [w for w in words if len(w) > 1]\n",
    "    sen_v = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            sen_v.append(model[word])\n",
    "        except:\n",
    "            continue\n",
    "    sen_v = np.array(sen_v)\n",
    "    sen_v = np.sum(sen_v, axis = 0)\n",
    "    return sen_v  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_VEC_DIM = 300\n",
    "\n",
    "def batch_sent_vec(model, sentences):\n",
    "    rows = len(sentences)\n",
    "    sents_matrix = np.zeros((rows, WORD_VEC_DIM))\n",
    "    for i in range(rows):\n",
    "        sents_matrix[i,:] = sentencVector(model, sentences[i])\n",
    "    return sents_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分组数据\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def grouper(iterable, n):\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip(*args)\n",
    "# 处理Y（回答）\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def deal_all_answer(answers):\n",
    "    labelEncoder = preprocessing.LabelEncoder()\n",
    "    labelEncoder.fit(answers)\n",
    "    return labelEncoder\n",
    "\n",
    "def get_answer_matrix(answers, encoder):\n",
    "    y = encoder.transform(answers)\n",
    "    Y = np_utils.to_categorical(y, encoder.classes_.shape[0])\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将图片的特征数据与句子的vector一起，作为输入数据传给MLP网络\n",
    "#读取数据：\n",
    "questions = open(\"./questions_train2014.txt\", \"r\").read().splitlines()\n",
    "img_ids = open(\"./images_train2014.txt\", \"r\").read().splitlines()\n",
    "answers = open(\"./answers_train2014_modal.txt\",\"r\").read().splitlines()\n",
    "#准备图片特征数据\n",
    "img_feature_struct, img_id_feature_map = generate_coco_image_feature(\"./vgg_feats.mat\", \"./coco_vgg_IDMap.txt\")\n",
    "\n",
    "index = (int)(len(questions) * 0.8)\n",
    "train_questions=questions[0:index]\n",
    "train_img_ids = img_ids[0:index]\n",
    "train_answers = answers[0:index]\n",
    "\n",
    "test_questions = questions[index:]\n",
    "test_img_ids = img_ids[index:]\n",
    "test_answers = answers[index:]\n",
    "\n",
    "#准备训练数据，从answers中找出频繁出现的1000个回答，再根据这些回答，找出train数据中的问题，图片，测试数据中的问题，图片\n",
    "from collections import defaultdict\n",
    "\n",
    "#1. 找出最频繁出现的1000个回答\n",
    "max_ans = 1000\n",
    "answers_all = defaultdict(int)\n",
    "for ans in train_answers:\n",
    "    answers_all[ans] += 1\n",
    "answers_all = sorted(answers_all.items(), key=operator.itemgetter(1), reverse= True)[0:max_ans]\n",
    "top_ans, top_freq = zip(*answers_all)\n",
    "q_new , img_new, ans_new = [], [], []\n",
    "\n",
    "#2.找出train数据中的问题，图片\n",
    "for q, img, ans in zip(train_questions, train_img_ids, train_answers):\n",
    "    if ans in top_ans:\n",
    "        q_new.append(q)\n",
    "        img_new.append(img)\n",
    "        ans_new.append(ans)\n",
    "\n",
    "train_questions_mlp  = q_new\n",
    "train_img_ids_mlp = img_new\n",
    "train_answers_mlp = ans_new\n",
    "\n",
    "#处理回答\n",
    "answers_encoder = deal_all_answer(train_answers_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP模型相关参数\n",
    "num_hidden_units = 1024\n",
    "num_hidden_layers = 3\n",
    "dropout = 0.5\n",
    "activation_fun = 'relu'\n",
    "# 图片的维度大小\n",
    "img_dim = 4096\n",
    "\n",
    "model_save_interval = 10\n",
    "batch_size = 128\n",
    "\n",
    "#建立模型\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(num_hidden_units, input_dim = img_dim + WORD_VEC_DIM, kernel_initializer='uniform'))\n",
    "model.add(Activation(activation_fun))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "#中间层\n",
    "for i in range(num_hidden_layers-1):\n",
    "    model.add(Dense(num_hidden_units, kernel_initializer='uniform'))\n",
    "    model.add(Activation(activation_fun))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "#输出层\n",
    "model.add(Dense(max_ans, kernel_initializer='uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存模型图\n",
    "#显示模型图片\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "\n",
    "def plot_and_show_model(model, file):\n",
    "    plot_model(model, to_file=file, show_shapes= True)\n",
    "    Image(filename=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172416/172471 [============================>.] - ETA: 0s - train loss: 4.1063"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from random import shuffle\n",
    "from keras.utils import generic_utils\n",
    "\n",
    "#只是看下效果\n",
    "num_epochs = 10\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    #准备数据\n",
    "    # 打乱数据的顺序\n",
    "    index_shuffle = [i for i in range(len(train_questions_mlp))]\n",
    "    shuffle(index_shuffle)\n",
    "    \n",
    "    train_questions_mlp = [train_questions_mlp[i] for i in index_shuffle]\n",
    "    train_img_ids_mlp = [train_img_ids_mlp[i] for i in index_shuffle]\n",
    "    train_answers_mlp = [train_answers_mlp[i] for i in index_shuffle]\n",
    "    \n",
    "    progbar = generic_utils.Progbar(len(train_questions_mlp))\n",
    "    \n",
    "    for ques_batch, img_batch, ans_batch in zip(grouper(train_questions_mlp, batch_size), grouper(train_img_ids_mlp, batch_size), grouper(train_answers_mlp, batch_size)):\n",
    "        \n",
    "        X_questions = batch_sent_vec(w2v_model, ques_batch)\n",
    "        X_img = get_image_matrix(img_feature_struct, img_id_feature_map, img_batch)\n",
    "        X = np.hstack((X_questions, X_img))\n",
    "        Y = get_answer_matrix(ans_batch, answers_encoder)\n",
    "        \n",
    "        loss = model.train_on_batch(X, Y)\n",
    "        progbar.add(batch_size, values=[(\"train loss\", loss)])\n",
    "        #保存中间训练的模型\n",
    "        if i % model_save_interval == 0 :\n",
    "            model.save_weights(\"vqa_mlp_model_epoch{:02d}.hdf5\".format(i))\n",
    "    \n",
    "model.save_weights(\"vqa_mlp_model_epoch{:02d}.hdf5\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_maxtrix_for_rnn(questions, timestep):\n",
    "    rows = len(questions)\n",
    "    q_mat = np.zeros((rows, timestep, WORD_VEC_DIM))\n",
    "    for i in range(rows):\n",
    "        words = word_tokenize(questions[i])\n",
    "        words = [word for word in words if len(word) > 1]\n",
    "        for j in range(len(words)):\n",
    "            if j < timestep:\n",
    "                try:\n",
    "                    M = w2v_model[words[j]]\n",
    "                    q_mat[i,j,:] = M\n",
    "                except:\n",
    "                    continue\n",
    "    return q_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, activation=\"relu\", kernel_initializer=\"uniform\")`\n"
     ]
    }
   ],
   "source": [
    "#建立模型：LSTM处理question, 然后再使用MLP\n",
    "# 参数们\n",
    "from keras.layers.core import Reshape\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Input\n",
    "from keras import Model\n",
    "\n",
    "max_qu_len = 30\n",
    "\n",
    "num_hidden_units_mlp = 1024\n",
    "num_hidden_units_lstm = 512\n",
    "num_hidden_layers_mlp = 3\n",
    "\n",
    "#建立一层或三层LSTM\n",
    "def vqa_lstm_mlp(is_one_layer,model_file):\n",
    "    img_input = Input(shape=(img_dim,))\n",
    "    img_model = Reshape((img_dim,), input_shape=(img_dim,))(img_input)\n",
    "\n",
    "    #语言模型\n",
    "    lan_input = Input(shape=(max_qu_len, WORD_VEC_DIM))\n",
    "    if is_one_layer:\n",
    "        lan_model = LSTM(units = num_hidden_units_lstm, return_sequences = False, input_shape=(max_qu_len, WORD_VEC_DIM))(lan_input)\n",
    "    else:\n",
    "        #输入层\n",
    "        lan_m1 = LSTM(units = num_hidden_units_lstm, return_sequences = True, input_shape=(max_qu_len, WORD_VEC_DIM))(lan_input)\n",
    "        lan_m2 = LSTM(units = num_hidden_units_lstm, return_sequences = True)(lan_m1)\n",
    "        lan_model = LSTM(units = num_hidden_units_lstm, return_sequences = False)(lan_m2)\n",
    "\n",
    "    concate_model = Concatenate(axis = 1)([lan_model, img_model])\n",
    "\n",
    "    hid_1 = Dense(num_hidden_units_mlp, init='uniform', activation=activation_fun)(concate_model)\n",
    "    drop_out_1 = Dropout(dropout)(hid_1)\n",
    "    hid_2 = Dense(num_hidden_units_mlp, init='uniform', activation=activation_fun)(drop_out_1)\n",
    "    drop_out_2 = Dropout(dropout)(hid_2)\n",
    "    hid_3 = Dense(num_hidden_units_mlp, init='uniform', activation=activation_fun)(drop_out_2)\n",
    "    drop_out_3 = Dropout(dropout)(hid_3)\n",
    "\n",
    "    out = Dense(max_ans, activation= 'softmax')(drop_out_3)\n",
    "\n",
    "    merge_mlp_model = Model(inputs=[lan_input, img_input], outputs= out)\n",
    "    #保存model\n",
    "    json_str = merge_mlp_model.to_json()\n",
    "    open(model_file,\"w\").write(json_str)\n",
    "\n",
    "    merge_mlp_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    return merge_mlp_model\n",
    "\n",
    "merge_mlp_model = vqa_lstm_mlp(True, \"./vqa_lstm_mlp_model.json\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "def train_model(model, num_epochs, get_qus_matrix_fun, model_weight_file_name, timesteps, train_questions_mlp, train_img_ids_mlp, train_answers_mlp):\n",
    "    for i in range(num_epochs):\n",
    "        progbar = generic_utils.Progbar(len(train_questions_mlp))\n",
    "\n",
    "        for ques_batch, img_batch, ans_batch in zip(grouper(train_questions_mlp, batch_size), grouper(train_img_ids_mlp, batch_size), grouper(train_answers_mlp, batch_size)):\n",
    "\n",
    "            X_questions = get_qus_matrix_fun(ques_batch, timesteps)\n",
    "            X_img = get_image_matrix(img_feature_struct, img_id_feature_map, img_batch)\n",
    "            X = [X_questions, X_img]\n",
    "            Y = get_answer_matrix(ans_batch, answers_encoder)\n",
    "\n",
    "            loss = model.train_on_batch(X, Y)\n",
    "            progbar.add(batch_size, values=[(\"train loss\", loss)])\n",
    "            #保存中间训练的模型\n",
    "            if i % model_save_interval == 0 :\n",
    "                model.save_weights(model_weight_file_name + \"_epoch{:02d}.hdf5\".format(i))\n",
    "    \n",
    "    model.save_weights(model_weight_file_name + \"_epoch{:02d}.hdf5\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172416/172471 [============================>.] - ETA: 0s - train loss: 3.9917"
     ]
    }
   ],
   "source": [
    "train_model(merge_mlp_model, 1, get_question_maxtrix_for_rnn, \"vqa_lstm_mlp_model_weight\", max_qu_len, train_questions_mlp, train_img_ids_mlp, train_answers_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, activation=\"relu\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172416/172471 [============================>.] - ETA: 1s - train loss: 3.8341"
     ]
    }
   ],
   "source": [
    "#可以再尝试下seq2seq (encode-decode,生成模型)\n",
    "# 加attention\n",
    "#bert, abert\n",
    "#1. 多层LSTM：3层\n",
    "lstm_3_model = vqa_lstm_mlp(False, \"./vqa_3_lstm_mlp_model.json\")\n",
    "train_model(lstm_3_model, 1, get_question_maxtrix_for_rnn, \"vqa_3_lstm_mlp_model_weight\", max_qu_len, train_questions_mlp, train_img_ids_mlp, train_answers_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#双向LSTM\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "def create_bidirect_lstm(one_layer, file_path, timestep, n_class):\n",
    "    #图片特征输入\n",
    "    img_input = Input(shape=(img_dim,))\n",
    "    img_model = Reshape((img_dim,), input_shape=(img_dim,))(img_input)\n",
    "    \n",
    "    #语言输入：\n",
    "    lan_input = Input(shape=(timestep, WORD_VEC_DIM))\n",
    "    if one_layer:\n",
    "        lan_model = Bidirectional(LSTM(units = num_hidden_units_lstm, return_sequences = False, input_shape=(timestep, WORD_VEC_DIM)))(lan_input)\n",
    "    else:\n",
    "        lan_1 = Bidirectional(LSTM(units = num_hidden_units_lstm, return_sequences = True, input_shape=(timestep, WORD_VEC_DIM)))(lan_input)\n",
    "        lan_model = Bidirectional(LSTM(units = num_hidden_units_lstm, return_sequences = False))(lan_1)\n",
    "    \n",
    "    #合并图片与语言特征\n",
    "    concate = Concatenate(axis=1)([lan_model, img_model])\n",
    "    \n",
    "    #MLP层 搭三层\n",
    "    lay1 = Dense(num_hidden_units_mlp, init='uniform',activation=activation_fun)(concate)\n",
    "    drop1 = Dropout(dropout)(lay1)\n",
    "    lay2 = Dense(num_hidden_units_mlp, init='uniform',activation=activation_fun)(drop1)\n",
    "    drop2 = Dropout(dropout)(lay2)\n",
    "    lay3 = Dense(num_hidden_units_mlp, init='uniform',activation=activation_fun)(drop2)\n",
    "    drop3 = Dropout(dropout)(lay3)\n",
    "    out = Dense(n_class, activation= 'softmax')(drop3)\n",
    "    \n",
    "    model = Model(inputs=[lan_input, img_input], outputs = out)\n",
    "     #保存model\n",
    "    json_str = model.to_json()\n",
    "    open(file_path,\"w\").write(json_str)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, activation=\"relu\", kernel_initializer=\"uniform\")`\n"
     ]
    }
   ],
   "source": [
    "timestep = 25\n",
    "model_bi_lstm = create_bidirect_lstm(True, \"./vqa_bi_lstm_mlp_model.json\", timestep, max_ans)\n",
    "model_2_bi_lstm = create_bidirect_lstm(True, \"./vqa_bi_lstm_mlp_model.json\", timestep, max_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172416/172471 [============================>.] - ETA: 0s - train loss: 3.1875"
     ]
    }
   ],
   "source": [
    "#train one bidrection lstm\n",
    "train_model(model_bi_lstm, 1, get_question_maxtrix_for_rnn, \"vqa_bi_lstm_mlp_model_weight\", timestep, train_questions_mlp, train_img_ids_mlp, train_answers_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172416/172471 [============================>.] - ETA: 0s - train loss: 3.2127"
     ]
    }
   ],
   "source": [
    "#train 2 bidrection lstm\n",
    "train_model(model_2_bi_lstm, 1, get_question_maxtrix_for_rnn, \"vqa_2_bi_lstm_mlp_model_weight\", timestep, train_questions_mlp, train_img_ids_mlp, train_answers_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
